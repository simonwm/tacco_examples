{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Variations for annotation using Optimal Transport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses TACCO with core annotation method OT and several parameter variations to show the dependence of the parameter choices on the quality of the annotation. The datasets are are taken from (Weinreb et al.) and (Avraham-Davidi et al.) or simulated using (Moriel) and (Kotliar).\n",
    "\n",
    "(Weinreb et al.): Weinreb C, Rodriguez-Fraticelli A, Camargo FD, Klein AM. Lineage tracing on transcriptional landscapes links state to fate during differentiation. Science. 2020 Feb 14;367(6479):eaaw3381. doi: 10.1126/science.aaw3381. Epub 2020 Jan 23. PMID: 31974159; PMCID: PMC7608074.\n",
    "\n",
    "(Avraham-Davidi et al.): Avraham-Davidi I, Mages S, Klughammer J, et al. Integrative single cell and spatial transcriptomics of colorectal cancer reveals multicellular functional units that support tumor progression. doi: https://doi.org/10.1101/2022.10.02.508492\n",
    "\n",
    "(Moriel): Moriel, N. Extension of scsim single-cell RNA-sequencing data simulations. github.com/nitzanlab/scsim-ext (2023)\n",
    "\n",
    "(Kotliar): Kotliar, D. scsim: simulate single-cell RNA-SEQ data using the Splatter statistical framework but implemented in python. github.com/dylkot/scsim (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import scipy.sparse\n",
    "from scsim import scsim\n",
    "\n",
    "import tacco as tc\n",
    "\n",
    "# The notebook expects to be executed either in the workflow directory or in the repository root folder...\n",
    "sys.path.insert(1, os.path.abspath('workflow' if os.path.exists('workflow/common_code.py') else '..')) \n",
    "import common_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = common_code.find_path('results/env_links')\n",
    "datasets = {} # collect all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differentiation_data_path = common_code.find_path('results/single_cell_differentiation/data')\n",
    "d4d6 = ad.read(f'{differentiation_data_path}/d4_d6_differentiation.h5ad')\n",
    "d2 = ad.read(f'{differentiation_data_path}/d2_differentiation.h5ad')\n",
    "datasets['Differentiation'] = { 'data': d2, 'ref': d4d6, 'ref_key': 'Cell type annotation', 'true_key': 'clone_fate', }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrnaseq_data_path = common_code.find_path('results/slideseq_mouse_colon/data')\n",
    "scrnaseq = ad.read(f'{scrnaseq_data_path}/scrnaseq.h5ad')\n",
    "datasets['Single cell'] = { 'data': scrnaseq, 'ref': scrnaseq, 'ref_key': 'labels', 'true_key': 'labels', }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-silico mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_rate = 1.0\n",
    "bead_shape = 'gauss'\n",
    "ntdata_max = 10**4\n",
    "bead_size = 1.0\n",
    "is_data = tc.tl.mix_in_silico(scrnaseq, type_key='labels', n_samples=ntdata_max, bead_shape=bead_shape, bead_size=bead_size, capture_rate=capture_rate,)\n",
    "is_data.obsm['reads_labels'] /= is_data.obsm['reads_labels'].to_numpy().sum(axis=1)[:,None]\n",
    "datasets['Mixture'] = { 'data': is_data, 'ref': scrnaseq, 'ref_key': 'labels', 'true_key': 'reads_labels', }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngenes = 25000\n",
    "descale = 1.0\n",
    "ndoublets = 100\n",
    "K = 13\n",
    "nproggenes = 1000\n",
    "proggroups = [1,2,3,4]\n",
    "progcellfrac = .35\n",
    "ncells = 1500\n",
    "deprob = .025\n",
    "\n",
    "seed = 111\n",
    "\n",
    "deloc = 2.0\n",
    "\n",
    "# simulating true counts (in simulator.counts)\n",
    "simulator = scsim(ngenes=ngenes, ncells=ncells, ngroups=K, libloc=7.64, libscale=0.78,\n",
    "             mean_rate=7.68,mean_shape=0.34, expoutprob=0.00286,\n",
    "             expoutloc=6.15, expoutscale=0.49,\n",
    "             diffexpprob=deprob, diffexpdownprob=0., diffexploc=deloc, diffexpscale=descale,\n",
    "             bcv_dispersion=0.448, bcv_dof=22.087, ndoublets=ndoublets,\n",
    "             nproggenes=nproggenes, progdownprob=0., progdeloc=deloc,\n",
    "             progdescale=descale, progcellfrac=progcellfrac, proggoups=proggroups,\n",
    "             minprogusage=.1, maxprogusage=.7, seed=seed)\n",
    "simulator.simulate()\n",
    "\n",
    "drop_ref = ad.AnnData(scipy.sparse.csr_matrix(simulator.counts), obs=simulator.cellparams, var=simulator.geneparams)\n",
    "drop_ref.obs['group'] = drop_ref.obs['group'].astype('category')\n",
    "\n",
    "dropshape, dropmidpoint = simulator.fit_dropout()\n",
    "\n",
    "simulator.dropshape = dropshape\n",
    "simulator.dropmidpoint = -1.0\n",
    "simulator.simulate_dropouts()\n",
    "\n",
    "drop_data = ad.AnnData(scipy.sparse.csr_matrix(simulator.countswdrop), obs=simulator.cellparams, var=simulator.geneparams)\n",
    "drop_data.obs['group'] = drop_data.obs['group'].astype('category')\n",
    "\n",
    "datasets['Dropout'] = { 'data': drop_data, 'ref': drop_ref, 'ref_key': 'group', 'true_key': 'group', }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ambient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngenes = 25000\n",
    "descale = 1.0\n",
    "ndoublets = 100\n",
    "K = 13\n",
    "nproggenes = 1000\n",
    "proggroups = [1,2,3,4]\n",
    "progcellfrac = .35\n",
    "ncells = 1500\n",
    "deprob = .025\n",
    "\n",
    "libloc=7.64\n",
    "libscale=0.78\n",
    "\n",
    "\n",
    "deloc = 5.0\n",
    "\n",
    "seed=2\n",
    "\n",
    "# simulating true counts (in simulator.counts)\n",
    "simulator = scsim(ngenes=ngenes, ncells=ncells, ngroups=K, libloc=libloc, libscale=libscale,\n",
    "             mean_rate=7.68,mean_shape=0.34, expoutprob=0.00286,\n",
    "             expoutloc=6.15, expoutscale=0.49,\n",
    "             diffexpprob=deprob, diffexpdownprob=0., diffexploc=deloc, diffexpscale=descale,\n",
    "             bcv_dispersion=0.448, bcv_dof=22.087, ndoublets=ndoublets,\n",
    "             nproggenes=nproggenes, progdownprob=0., progdeloc=deloc,\n",
    "             progdescale=descale, progcellfrac=progcellfrac, proggoups=proggroups,\n",
    "             cellbender=True, cb_ambient=False, #cb_droploc=0, cb_dropscale=1, \n",
    "                  cb_dispshape=1, cb_dispscale=1,\n",
    "             minprogusage=.1, maxprogusage=.7, seed=seed)\n",
    "simulator.simulate()\n",
    "\n",
    "amb_ref = ad.AnnData(simulator.counts, obs=simulator.cellparams, var=simulator.geneparams[[]])\n",
    "amb_ref.obs['group'] = amb_ref.obs['group'].astype('category')\n",
    "\n",
    "# get counts with ambient RNA (cellbender)\n",
    "simulator.cb_ambient=True\n",
    "\n",
    "simulator.cb_fraclib = 0.2\n",
    "simulator.simulate_cellbender()\n",
    "\n",
    "amb_data = ad.AnnData(simulator.counts, obs=simulator.cellparams, var=simulator.geneparams[[]])\n",
    "amb_data.obs['group'] = amb_data.obs['group'].astype('category')\n",
    "\n",
    "datasets['Ambient'] = { 'data': amb_data, 'ref': amb_ref, 'ref_key': 'group', 'true_key': 'group', }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highres = False\n",
    "default_dpi = 100.0 # matplotlib.rcParams['figure.dpi']\n",
    "if highres:\n",
    "    matplotlib.rcParams['figure.dpi'] = 648.0\n",
    "    hr_ext = '_hd'\n",
    "else:\n",
    "    matplotlib.rcParams['figure.dpi'] = default_dpi\n",
    "    hr_ext = ''\n",
    "\n",
    "axsize = np.array([4,3])*0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a set of parameters and use them to annotate all collected datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    'TACCO': {'method': 'OT', 'metric':'bc', 'multi_center': 10, 'platform_iterations': 0,'bisections':4, 'bisection_divisor':3,},\n",
    "    'TACCO w/ cosine metric': {'method': 'OT', 'metric':'cosine', 'multi_center': 10, 'platform_iterations': 0,'bisections':4, 'bisection_divisor':3,},\n",
    "    'TACCO w/ cosine metric, log-normalization': {'method': 'OT', 'metric':'cosine', 'log_norm': True, 'multi_center': 10, 'platform_iterations': 0,'bisections':4, 'bisection_divisor':3,},\n",
    "    'TACCO w/o platform normalization': {'method': 'OT', 'metric':'bc', 'multi_center': 10, 'bisections':4, 'bisection_divisor':3, 'platform_iterations': -1,},\n",
    "    'TACCO w/o multicenter': {'method': 'OT', 'metric':'bc', 'platform_iterations': 0,'bisections':4, 'bisection_divisor':3,},\n",
    "    'TACCO w/o bisection': {'method': 'OT', 'metric':'bc', 'multi_center': 10,'bisections':0,'platform_iterations': 0,},\n",
    "}\n",
    "\n",
    "for dname,dataset in datasets.items():\n",
    "    for method,params in methods.items():\n",
    "        print(f'running method {method!r} on data {dname!r}')\n",
    "        try:\n",
    "            tc.tl.annotate(dataset['data'], dataset['ref'], annotation_key=dataset['ref_key'], result_key=method, **params, assume_valid_counts=True,verbose=0)\n",
    "        except:\n",
    "            pass # catch failing methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for dname,dataset in datasets.items():\n",
    "    for method,params in methods.items():\n",
    "        results[(dname,method)] = {}\n",
    "        results[(dname,method)]['l2'] = tc.ev.compute_err(dataset['data'], method, dataset['true_key'], err_method='lp', p=2)[method]\n",
    "        results[(dname,method)]['max_correct'] = tc.ev.compute_err(dataset['data'], method, dataset['true_key'], err_method='max_correct')[method]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame([\n",
    "    [dname,method,v['l2'],1-v['max_correct'],]\n",
    "    for (dname,method),v in results.items()\n",
    "],columns=['dataset','method','L2 error','max error rate'])\n",
    "res_df['dataset'] = res_df['dataset'].astype(pd.CategoricalDtype(categories=['Single cell', 'Mixture', 'Dropout', 'Ambient', 'Differentiation', ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "all_method_names = res_df['method'].unique()\n",
    "quantities = ['L2 error','max error rate',]\n",
    "\n",
    "comparisons = {\n",
    "    'metric': ['TACCO', 'TACCO w/ cosine metric', 'TACCO w/ cosine metric, log-normalization'],\n",
    "    'platform normalization': ['TACCO', 'TACCO w/o platform normalization'],\n",
    "    'multicenter': ['TACCO', 'TACCO w/o multicenter'],\n",
    "    'bisection': ['TACCO', 'TACCO w/o bisection',],\n",
    "}\n",
    "\n",
    "fig,axs = tc.pl.subplots(len(comparisons),len(quantities), axsize=axsize, x_padding=0.2, y_padding=0.2, sharey='row')\n",
    "colors = {m:common_code.method_color(m) for m in all_method_names}\n",
    "\n",
    "for jx_ax,(comp, method_names) in enumerate(comparisons.items()):\n",
    "    res_sub = res_df.loc[~res_df[quantities].isna().all(axis=1)]\n",
    "    res_sub = res_sub[res_sub['method'].isin(method_names)].copy()\n",
    "    res_sub['method'] = res_sub['method'].astype(str)\n",
    "    for iy_ax, qty in enumerate(quantities):\n",
    "        ax = axs[iy_ax,jx_ax]\n",
    "\n",
    "        sns.barplot(x=\"dataset\", y=qty, hue=\"method\", data=res_sub, ax=ax, palette=[colors[m] for m in method_names])\n",
    "        \n",
    "        ax.set_xticks(np.arange(len(res_sub['dataset'].cat.categories)))\n",
    "        ax.set_xticklabels([])\n",
    "        if iy_ax == 0:\n",
    "            ax.set_title(f'{comp}')\n",
    "            ax.set_xlabel(None)\n",
    "        elif iy_ax == axs.shape[0] - 1:\n",
    "            ax.set_xticklabels(res_sub['dataset'].cat.categories, rotation=90)\n",
    "            ax.set_xlabel('dataset')\n",
    "        if jx_ax == 0:\n",
    "            ax.set_ylabel(f'{qty}')\n",
    "        else:\n",
    "            ax.set_ylabel(None)\n",
    "        \n",
    "        ax.get_legend().remove()\n",
    "        if iy_ax == 0 and jx_ax == axs.shape[1] - 1:\n",
    "            import matplotlib.lines as mlines\n",
    "            ax.legend(handles=[matplotlib.patches.Patch(color=color, label=ind) for (ind, color) in colors.items() ],\n",
    "                bbox_to_anchor=(1, 1), loc='upper left', ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
