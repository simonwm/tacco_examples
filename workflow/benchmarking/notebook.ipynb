{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking runtime and memory of annotation methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example benrchmarks runtime and memory requirements for annotating different datasets with different methods. The datasets are are taken from (Weinreb et al.) and (Avraham-Davidi et al.) or simulated using (Moriel) and (Kotliar).\n",
    "\n",
    "(Weinreb et al.): Weinreb C, Rodriguez-Fraticelli A, Camargo FD, Klein AM. Lineage tracing on transcriptional landscapes links state to fate during differentiation. Science. 2020 Feb 14;367(6479):eaaw3381. doi: 10.1126/science.aaw3381. Epub 2020 Jan 23. PMID: 31974159; PMCID: PMC7608074.\n",
    "\n",
    "(Avraham-Davidi et al.): Avraham-Davidi I, Mages S, Klughammer J, et al. Integrative single cell and spatial transcriptomics of colorectal cancer reveals multicellular functional units that support tumor progression. doi: https://doi.org/10.1101/2022.10.02.508492\n",
    "\n",
    "(Moriel): Moriel, N. Extension of scsim single-cell RNA-sequencing data simulations. github.com/nitzanlab/scsim-ext (2023)\n",
    "\n",
    "(Kotliar): Kotliar, D. scsim: simulate single-cell RNA-SEQ data using the Splatter statistical framework but implemented in python. github.com/dylkot/scsim (2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tacco as tc\n",
    "\n",
    "# The notebook expects to be executed either in the workflow directory or in the repository root folder...\n",
    "sys.path.insert(1, os.path.abspath('workflow' if os.path.exists('workflow/common_code.py') else '..')) \n",
    "import common_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axsize = np.array([4,3])*0.5\n",
    "\n",
    "def plot_benchmark_results(res, purpose):\n",
    "\n",
    "    res['dataset'] = res['dataset'].astype(pd.CategoricalDtype(['Mixture','Dropout','Differentiation'], ordered=True))\n",
    "    res = res.sort_values(['dataset','Ndat'])\n",
    "    \n",
    "    res['time (s)'] = res['annotation_time_s']\n",
    "    res['memory (GB)'] = res['max_mem_usage_GB']\n",
    "    res['L2 error'] = res['L2']\n",
    "    \n",
    "    methods = res['method'].unique()\n",
    "    n_dnames = len(res['dataset'].unique())\n",
    "    \n",
    "    quantities = ['time (s)','memory (GB)','L2 error']\n",
    "    fig,axs = tc.pl.subplots(n_dnames,len(quantities), axsize=axsize, x_padding=0.7, y_padding=0.5)\n",
    "    colors = {m:common_code.method_color(m) for m in methods}\n",
    "    styles = {m:common_code.method_style(m) for m in methods}\n",
    "    for jx_ax, (dname, res1) in enumerate(res.groupby('dataset')):\n",
    "        res1 = res1.loc[~res1[quantities].isna().all(axis=1)]\n",
    "        for iy_ax, qty in enumerate(quantities):\n",
    "            ax = axs[iy_ax,jx_ax]\n",
    "\n",
    "            x = res1['Ndat']\n",
    "            y = res1[qty]\n",
    "\n",
    "            if qty == 'time (s)': # part 1 of adding second, minute and hour marker: plot the lines under the data\n",
    "\n",
    "                ynew = np.array([0.1,1,10,60,600,3600,36000])\n",
    "                ynew_minor = np.concatenate([np.arange(0.1,1,0.1),np.arange(1,10,1),np.arange(10,60,10),np.arange(60,600,60),np.arange(600,3600,600),np.arange(3600,36000,3600)]).flatten()\n",
    "                ynewlabels = np.array(['0.1s','1s','10s','1min','10min','1h','10h'])\n",
    "                if purpose == 'cross_methods':\n",
    "                    ymin, ymax = 9, 44000\n",
    "                else:\n",
    "                    ymin, ymax = 3, 3600\n",
    "                ynewlabels = ynewlabels[(ynew > ymin) & (ynew < ymax)]\n",
    "                ynew = ynew[(ynew > ymin) & (ynew < ymax)]\n",
    "                ynew_minor = ynew_minor[(ynew_minor > ymin) & (ynew_minor < ymax)]\n",
    "                for yn in ynew:\n",
    "                    ax.axhline(yn, color='gray', linewidth=0.5)\n",
    "\n",
    "            elif qty == 'memory (GB)':\n",
    "\n",
    "                ynew = np.array([0.1,0.4,1,4,10,40,100])\n",
    "                ynew_minor = np.concatenate([np.arange(0.1,1,0.1),np.arange(1,10,1),np.arange(10,100,10),np.arange(100,1000,100)]).flatten()\n",
    "                ynewlabels = np.array(['0.1GB','0.4GB','1GB','4GB','10GB','40GB','100GB'])\n",
    "                ymin, ymax = 0.7, 101\n",
    "                ynewlabels = ynewlabels[(ynew > ymin) & (ynew < ymax)]\n",
    "                ynew = ynew[(ynew > ymin) & (ynew < ymax)]\n",
    "                ynew_minor = ynew_minor[(ynew_minor > ymin) & (ynew_minor < ymax)]\n",
    "                for yn in ynew:\n",
    "                    ax.axhline(yn, color='gray', linewidth=0.5)\n",
    "\n",
    "            for m in methods:\n",
    "                selector = res1['method'] == m\n",
    "                if selector.sum() == 0:\n",
    "                    continue\n",
    "                zorder_args = {}\n",
    "                if purpose != 'cross_methods' and m == 'TACCO':\n",
    "                    zorder_args['zorder'] = 2.5\n",
    "                ax.plot(x[selector],y[selector],marker='o',color=colors[m],ls=styles[m],label=m, **zorder_args)\n",
    "            if iy_ax == 0:\n",
    "                ax.set_title(f'{dname}')\n",
    "            elif iy_ax == axs.shape[0] - 1:\n",
    "                ax.set_xlabel('number of observations')\n",
    "            if jx_ax == 0:\n",
    "                if qty == 'time (s)':\n",
    "                    ax.set_ylabel('runtime')\n",
    "                elif qty == 'memory (GB)':\n",
    "                    ax.set_ylabel('memory')\n",
    "                else:\n",
    "                    ax.set_ylabel(f'{qty}')\n",
    "            if qty in ['time (s)','memory (GB)']:\n",
    "                ax.set_yscale('log')\n",
    "            ax.set_xscale('log')\n",
    "\n",
    "            if qty in ['time (s)','memory (GB)']: # part 2 off adding second, minute and hour marker: add the second y axis after rescaling the first y axis to log scale\n",
    "                ax.set_yticks(ynew_minor,minor=True)\n",
    "                ax.set_yticks(ynew)\n",
    "                ax.set_yticklabels(ynewlabels)\n",
    "                ax.set_yticklabels([],minor=True)\n",
    "                ax.set_ylim((ymin,ymax))\n",
    "\n",
    "            if iy_ax == 0 and jx_ax == axs.shape[1] - 1:\n",
    "                ax.legend(bbox_to_anchor=(1, 1), loc='upper left', ncol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross method comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running all the methods on all datasets across all problem sizes takes quit a while and is therefore outsourced to the Snakemake workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = common_code.find_path('results/benchmarking')\n",
    "cross_method_results = pd.read_csv(f'{results_path}/cross_methods.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "plot_benchmark_results(cross_method_results, purpose='cross_methods')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross parameter comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running all parameter variations on all datasets across all problem sizes takes quit a while and is therefore outsourced to the Snakemake workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = common_code.find_path('results/benchmarking')\n",
    "cross_params_results = pd.read_csv(f'{results_path}/cross_params.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_benchmark_results(cross_params_results, purpose='cross_params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
